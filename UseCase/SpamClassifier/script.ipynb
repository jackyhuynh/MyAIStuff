{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a909cf",
   "metadata": {},
   "source": [
    "# Supervised Learning: Classification: Navie Bayes\n",
    "\n",
    "### Explain the problem:\n",
    "\n",
    "Using of Naive Bayes is to try and detect [spam emails](https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering). Spam email is annoying and can lead to open backdoor, fishing and other harmful to the users. Detecting ontime can save user to protect their data, freedom, privacy and financial.\n",
    "\n",
    "### Data Source:\n",
    "\n",
    "I will be using dataset that of emails from the [Enron Corporation](https://en.wikipedia.org/wiki/Enron_Corpus), an accounting firm that [went bankrupt in 2001 due to an accounting scandal](https://en.wikipedia.org/wiki/Enron_scandal).\n",
    "\n",
    "This is one project I build when studied at AI Academy (NCSU.edu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632acd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# set a seed for reproducibility\n",
    "random_seed = 25\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739bbf6",
   "metadata": {},
   "source": [
    "## 1) Exploratory data analyst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ec56dd",
   "metadata": {},
   "outputs": [],
   "source": "df = pd.read_csv(\"enron_emails.csv\")"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a405b037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject: put the 10 on the ft\\nthe transport v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\nhpl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject: calpine daily gas nomination\\n&gt;\\n&gt;\\nj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>spam</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject: important online banking alert\\ndear ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  label_num                                               text\n",
       "0      ham          0  Subject: enron methanol ; meter # : 988291\\nth...\n",
       "1      ham          0  Subject: hpl nom for january 9 , 2001\\n( see a...\n",
       "2      ham          0  Subject: neon retreat\\nho ho ho , we ' re arou...\n",
       "3     spam          1  Subject: photoshop , windows , office . cheap ...\n",
       "4      ham          0  Subject: re : indian springs\\nthis deal is to ...\n",
       "...    ...        ...                                                ...\n",
       "5166   ham          0  Subject: put the 10 on the ft\\nthe transport v...\n",
       "5167   ham          0  Subject: 3 / 4 / 2000 and following noms\\nhpl ...\n",
       "5168   ham          0  Subject: calpine daily gas nomination\\n>\\n>\\nj...\n",
       "5169   ham          0  Subject: industrial worksheets for august 2000...\n",
       "5170  spam          1  Subject: important online banking alert\\ndear ...\n",
       "\n",
       "[5171 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4411ef49",
   "metadata": {},
   "source": [
    "**Explain:**\n",
    "\n",
    "A ham email is a legitimate email, while a spam email is unwanted (in label columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd1951e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3672\n",
       "spam    1499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()\n",
    "# There are 3672 legit email and 1499 spam email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31960134",
   "metadata": {},
   "source": [
    "**Explain:**\n",
    "\n",
    "Since the data is label. we are going to use supervised learning, classification naives bayes to solve the problem. and our model will be Bag-of-words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "798ce723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: re : indian springs\n",
      "this deal is to book the teco pvr revenue . it is my understanding that teco\n",
      "just sends us a check , i haven ' t received an answer as to whether there is a\n",
      "predermined price associated with this deal or if teco just lets us know what\n",
      "we are giving . i can continue to chase this deal down if you need .\n"
     ]
    }
   ],
   "source": [
    "# Let's explore some of the ham emails...\n",
    "\n",
    "print(df[df[\"label\"]==\"ham\"].text.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f3512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: back\n",
      "emile (\n",
      "the cablefilterz will allow you to receive\n",
      "all the channels that you order with your remote control ,\n",
      "payperviews , axxxmovies , sport events , special - events !\n",
      "http : / / www . 8006 hosting . com / cable /\n",
      "avocation , despoil .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And now the spam emails...\n",
    "\n",
    "print(df[df[\"label\"]==\"spam\"].text.iloc[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e369154",
   "metadata": {},
   "source": [
    "## 2) AI Model: Bag-of-words:\n",
    "\n",
    "The bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity. \n",
    "\n",
    "The bag-of-words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.[2]\n",
    "\n",
    "Retrieved from https://en.wikipedia.org/wiki/Bag-of-words_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea79658",
   "metadata": {},
   "source": [
    "### CountVectorizer from sklearn:\n",
    "\n",
    "We also use The CountVectorizer. it's fit_transform method returns a NxM matrix. N is the number of documents (sentences) you have in your corpus, and M is the number of unique words in your corpus. Item nxm is how many times word m appears in document n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f7246",
   "metadata": {},
   "source": [
    "### Build the model:\n",
    "\n",
    "Build a Naive Bayes Classifier and evaluate it on a train and test set. In this instance, Multinomial Naive Bayes classifier, which is most useful for discrete features that use frequency counts (e.g. a bag of words vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7a66858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84d9fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the label so we not have any biased\n",
    "df = df.drop(['label'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f80e39e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_num</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_num                                               text\n",
       "0          0  Subject: enron methanol ; meter # : 988291\\nth...\n",
       "1          0  Subject: hpl nom for january 9 , 2001\\n( see a...\n",
       "2          0  Subject: neon retreat\\nho ho ho , we ' re arou...\n",
       "3          1  Subject: photoshop , windows , office . cheap ...\n",
       "4          0  Subject: re : indian springs\\nthis deal is to ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65e95d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test splits\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Since this is supervised learning, we need to spilt the data into train and test data set\n",
    "# train data set will contain label (ham/spam or 0/1)\n",
    "# test data will not contain label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b889b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize on your training data using BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(train.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cdc48d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier below\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X,train.label_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a05791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize your test data using transform and then predict the test data\n",
    "test_vecs = vectorizer.transform(test.text)\n",
    "predictions = clf.predict(test_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50201304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[728,   6],\n",
       "       [ 11, 290]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a confusion matrix\n",
    "confusion_matrix(test.label_num,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a778a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       734\n",
      "           1       0.98      0.96      0.97       301\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.98      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(classification_report(test.label_num,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf4203",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "- We just create a model with the precision of 98% on predicting spam email (precision score)\n",
    "- I will explain further below on how we can do that\n",
    "\n",
    "**Technical Note: Log Probabilities**: \n",
    "\n",
    "When using probabilistic methods with large datasets, sometimes you get features with extremely small probabilities (e.g. $10^{-10}$). \n",
    "\n",
    "This becomes a problem, because computers aren't really good at doing operations with numbers at this scale. Therefore, in most systems, operations are done on the *log* of the probabilities. \n",
    "\n",
    "This makes calculations much more managable (e.g. $\\log(10^{-10})=-10$). As an added bonus, due to log rules ($log(ab)=log(a)+log(b)$), all multiplications turn into additions, which are easier for the computer.\n",
    "\n",
    "Some general rules of thumb: **the closer to zero a log prob is, the more probabable it is**, and **each time a log prob decreases by one, it's an order of magnitude less probable**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12ac90",
   "metadata": {},
   "source": [
    "### Exploring Important Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db7de2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.75023447,  -5.71398455, -11.28296498, ..., -13.07472445,\n",
       "       -13.07472445, -13.07472445])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given that a message is ham, how probable is it for the words to show up?\n",
    "clf.feature_log_prob_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2545eff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.23363088,  -7.07284789,  -9.8691907 , ..., -11.74099287,\n",
       "       -11.74099287, -11.74099287])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given that a message is SPAM, how probable is it for the words to show up?\n",
    "clf.feature_log_prob_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8d43096",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_args = np.argsort(clf.feature_log_prob_[1])\n",
    "spam_words = np.array(vectorizer.get_feature_names())[spam_args]\n",
    "spam_words = np.flip(spam_words)\n",
    "\n",
    "#Is this flipped or is this wrong\n",
    "ham_args = np.argsort(clf.feature_log_prob_[0])\n",
    "ham_words = np.array(vectorizer.get_feature_names())[ham_args]\n",
    "ham_words = np.flip(spam_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b1ae85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're operating on logs, division turns into subtraction\n",
    "log_odds = clf.feature_log_prob_[1] - clf.feature_log_prob_[0]\n",
    "spam_ham_args = np.argsort(log_odds)\n",
    "spam_ham_words = np.array(vectorizer.get_feature_names())[spam_ham_args]\n",
    "spam_ham_words = np.flip(spam_ham_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fca74ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['td', 'nbsp', 'pills', 'width', 'computron', 'br', 'font', 'href',\n",
       "       'viagra', 'height', 'xp', 'src', '2004', 'cialis', 'soft', 'meds',\n",
       "       'paliourg', 'php', 'voip', 'drugs', 'oo', 'valign', 'bgcolor',\n",
       "       'biz', 'hotlist', 'moopid', 'div', 'photoshop', 'mx', 'img',\n",
       "       'knle', 'pharmacy', 'gr', 'intel', 'corel', 'prescription', 'iit',\n",
       "       'demokritos', 'rolex', 'xanax', 'macromedia', 'dealer',\n",
       "       'uncertainties', 'valium', 'htmlimg', 'darial', '000000',\n",
       "       '0310041', 'lots', 'projections', 'jebel', 'adobe', 'rnd', 'color',\n",
       "       'alt', '161', 'colspan', 'pain', 'readers', 'rx', 'canon',\n",
       "       'export', 'draw', 'fontfont', 'gra', 'speculative', '1226030',\n",
       "       'gold', 'pro', 'logos', 'wi', 'toshiba', 'china', '1933', 'spam',\n",
       "       'vicodin', 'itoy', 'viewsonic', 'ooking', '1618', 'cellpadding',\n",
       "       'weight', 'hewlett', '4176', 'pill', 'robotics', 'soma',\n",
       "       'resellers', '8834464', '8834454', 'apc', 'intellinet', 'aopen',\n",
       "       'iomega', 'enquiries', 'customerservice', 'targus', 'packard',\n",
       "       'tr', 'uae', 'dealers', 'spain', 'nomad', '1934', 'drug', 'muscle',\n",
       "       'abdv', 'zonedubai', 'eogi', 'aeor', 'doctors', 'inherent',\n",
       "       'wysak', 'emirates', 'cheap', 'health', 'border', 'illustrator',\n",
       "       'hottlist', 'oem', 'apple', 'ffffff', 'ce', 'verdana', 'sex',\n",
       "       'gif', 'resuits', 'graphics', 'mining', 'studio', 'differ',\n",
       "       'materia', 'predictions', 'arial', 'waste', 'cellspacing', 'yap',\n",
       "       'male', 'phentermine', 'tirr', 'cf', 'wiil', 'construed', 'otcbb',\n",
       "       'atleast', 'materially', 'kin', '2005', 'vi', 'anticipates',\n",
       "       'erections', 'artprice', 'deciding', 'featured', 'prescriptions',\n",
       "       'sofftwaares', 'ali', 'ur', 'sir', 'discreet', 'gains', 'dose',\n",
       "       'cia', 'assurance', 'distributorjebel', 'nigeria', 'spur',\n",
       "       'serial', 'ambien', 'creative', 'align', 'stocks', 'aerofoam',\n",
       "       'der', 'penis', 'emerson', 'bingo', 'ffffffstrongfont', 'mai',\n",
       "       'style', 'anxiety', 'brbr', 'prozac', 'undervalued', 'epson',\n",
       "       'fontbr', 'notebook', 'levitra', 'es', 'iso', 'risks', 'alcohol',\n",
       "       'xm', 'erection', 'lasts', 'effects', 'vlagra', 'technoiogies',\n",
       "       '124', 'couid'], dtype='<U24')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_x=200\n",
    "spam_ham_words[0:top_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10a67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
